{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "02_run",
      "provenance": [],
      "collapsed_sections": [
        "cDjCZ1hHEHmS",
        "BMH14x2OFA0c"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkCBYJgyvGAc"
      },
      "source": [
        "from google.colab import files, drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9fQSNVrwreY"
      },
      "source": [
        "DRIVE_BASE_DIR = '/SMC 09/DDSP' \n",
        "INSTRUMENTS_FOLDER = 'instruments'\n",
        "EXAMPLES_FOLDER = 'examples'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDjCZ1hHEHmS"
      },
      "source": [
        "#Install, import and setup files\n",
        "1.   Install DDSP\n",
        "2.   Import Python libraries\n",
        "3.   Copy instruments and examples to Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhqoaVStEDaj"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp==1.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMZI6KnSEjAG"
      },
      "source": [
        "import warnings\n",
        "import copy\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import gin\n",
        "import librosa\n",
        "import pickle\n",
        "import crepe\n",
        "import ddsp\n",
        "import ddsp.training\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from ddsp.colab import colab_utils\n",
        "from ddsp.colab.colab_utils import (\n",
        "    auto_tune, detect_notes, fit_quantile_transform, \n",
        "    get_tuning_factor, download, play, record, audio_bytes_to_np,\n",
        "    specplot, upload, DEFAULT_SAMPLE_RATE)\n",
        "from google.colab import files\n",
        "from ipywidgets import interact\n",
        "from IPython.display import Javascript\n",
        "\n",
        "\n",
        "sample_rate = DEFAULT_SAMPLE_RATE  # 16000\n",
        "\n",
        "\n",
        "#Use retina mode\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "#Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Set some globals\n",
        "REALEXAMPLE = ''\n",
        "REALINSTRUMENT = ''\n",
        "audio = None\n",
        "audio_features = None\n",
        "audio_features_mod = None\n",
        "ckpt = None\n",
        "model = None\n",
        "DATASET_STATS = None\n",
        "\n",
        "TRIM = -15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7MO01A1_JMY"
      },
      "source": [
        "DRIVE_BASE_DIR = '/content/drive/My Drive' + DRIVE_BASE_DIR\n",
        "EXAMPLES_DIR = DRIVE_BASE_DIR + '/' + EXAMPLES_FOLDER\n",
        "assert os.path.exists(EXAMPLES_DIR)\n",
        "COLAB_EXAMPLES_DIR = 'data/examples' \n",
        "!mkdir -p $COLAB_EXAMPLES_DIR\n",
        "\n",
        "mp3_files = glob.glob(os.path.join(EXAMPLES_DIR, '*.mp3'))\n",
        "wav_files = glob.glob(os.path.join(EXAMPLES_DIR, '*.wav'))\n",
        "audio_files = mp3_files + wav_files\n",
        "example_file_list = [os.path.basename(file) for file in (audio_files)]\n",
        "example_file_list.sort()\n",
        "\n",
        "print(\"Copying {} examples\".format(len(example_file_list)))\n",
        "for fname in audio_files:\n",
        "    target_name = os.path.join(COLAB_EXAMPLES_DIR, \n",
        "                               os.path.basename(fname).replace(' ', '_').replace('\\'', '_'))\n",
        "    #print('  {}'.format(target_name))\n",
        "    !cp \"$fname\" $target_name\n",
        "\n",
        "\n",
        "INSTRUMENTS_DIR = DRIVE_BASE_DIR + '/' + INSTRUMENTS_FOLDER\n",
        "assert os.path.exists(INSTRUMENTS_DIR)\n",
        "COLAB_INSTRUMENTS_DIR = 'data/instruments' \n",
        "!mkdir -p $COLAB_INSTRUMENTS_DIR\n",
        "\n",
        "zip_files = glob.glob(os.path.join(INSTRUMENTS_DIR, '*.zip'))\n",
        "instrument_file_list = [os.path.basename(file) for file in (zip_files)]\n",
        "instrument_file_list.sort()\n",
        "\n",
        "print(\"Copying {} instruments\".format(len(instrument_file_list)))\n",
        "for fname in zip_files:\n",
        "    target_name = os.path.join(COLAB_INSTRUMENTS_DIR, \n",
        "                               os.path.basename(fname).replace(' ', '_').replace('\\'', '_'))\n",
        "    #print('  {}'.format(target_name))\n",
        "    !cp \"$fname\" $target_name\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMH14x2OFA0c"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCpZbpQZP8Ry"
      },
      "source": [
        "def load_instrument(instrument_name):\n",
        "\n",
        "  global REALINSTRUMENT, model, ckpt, DATASET_STATS\n",
        "\n",
        "  if (REALINSTRUMENT!=instrument_name):\n",
        "    print('Loading the model...')\n",
        "    REALINSTRUMENT=instrument_name\n",
        "    start_time = time.time()\n",
        "    \n",
        "    COLAB_MODEL_DIR = COLAB_INSTRUMENTS_DIR + '/current'\n",
        "    print(f'Unziping {instrument_name}')\n",
        "    !rm -r $COLAB_MODEL_DIR\n",
        "    !unzip -j $COLAB_INSTRUMENTS_DIR'/'$instrument_name -d $COLAB_MODEL_DIR &> /dev/null\n",
        "  \n",
        "    #gin file\n",
        "    gin_file = os.path.join(COLAB_MODEL_DIR, 'operative_config-0.gin')\n",
        "    with gin.unlock_config():\n",
        "      gin.parse_config_file(gin_file, skip_unknown=True)\n",
        "\n",
        "    #stats\n",
        "    dataset_stats_file = os.path.join(COLAB_MODEL_DIR, 'dataset_statistics.pkl')\n",
        "    print(f'Loading dataset statistics from {dataset_stats_file}')\n",
        "    try:\n",
        "      if tf.io.gfile.exists(dataset_stats_file):\n",
        "        with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
        "          DATASET_STATS = pickle.load(f)\n",
        "      else:\n",
        "          print('WARNING: pickle file not present')\n",
        "          DATASET_STATS = None\n",
        "    except Exception as err:\n",
        "      print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
        "  \n",
        "    #checkpoints\n",
        "    ckpt_files = [f for f in tf.io.gfile.listdir(COLAB_MODEL_DIR) if 'ckpt' in f]\n",
        "    ckpt_name = ckpt_files[0].split('.')[0]\n",
        "    ckpt = os.path.join(COLAB_MODEL_DIR, ckpt_name)\n",
        "    print('Restoring checkpoint %s took %.1f seconds' % (ckpt_name, time.time() - start_time))\n",
        "\n",
        "    if REALEXAMPLE != '' and REALINSTRUMENT != '':\n",
        "      print(\"Restoring model from load_instrument\")\n",
        "      restore_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zHRDn7fFElh"
      },
      "source": [
        "def load_example(example_name):\n",
        "\n",
        "  global REALEXAMPLE, audio, audio_features\n",
        "\n",
        "  if (REALEXAMPLE!=example_name):\n",
        "    print('Loading audio and extracting features...')\n",
        "    REALEXAMPLE=example_name\n",
        "    start_time = time.time()\n",
        "\n",
        "    with open(COLAB_EXAMPLES_DIR+'/'+REALEXAMPLE, 'rb') as fd:\n",
        "      contents = fd.read()\n",
        "\n",
        "    audio = audio_bytes_to_np(contents, sample_rate=DEFAULT_SAMPLE_RATE, normalize_db=None)\n",
        "    audio = audio[np.newaxis, :]\n",
        "\n",
        "    #Compute features.\n",
        "    ddsp.spectral_ops.reset_crepe()\n",
        "    audio_features = ddsp.training.metrics.compute_audio_features(audio)\n",
        "    audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
        "    print('Operation took %.1f seconds' % (time.time() - start_time))\n",
        "\n",
        "    if REALEXAMPLE != '' and REALINSTRUMENT != '':\n",
        "      print(\"Restoring model from load_example\")\n",
        "      restore_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y4Y3DGGgXMf"
      },
      "source": [
        "def restore_model():\n",
        "  global model, audio_features, ckpt\n",
        "\n",
        "  #Ensure dimensions and sampling rates are equal\n",
        "  time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
        "  n_samples_train = gin.query_parameter('Harmonic.n_samples')\n",
        "  hop_size = int(n_samples_train / time_steps_train)\n",
        "\n",
        "  time_steps = int(audio.shape[1] / hop_size)\n",
        "  n_samples = time_steps * hop_size\n",
        "\n",
        "  gin_params = [\n",
        "      'Harmonic.n_samples = {}'.format(n_samples),\n",
        "      'FilteredNoise.n_samples = {}'.format(n_samples),\n",
        "      'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
        "      'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
        "  ]\n",
        "\n",
        "  with gin.unlock_config():\n",
        "    gin.parse_config(gin_params)\n",
        "\n",
        "  # Trim all input vectors to correct lengths \n",
        "  for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
        "      audio_features[key] = audio_features[key][:time_steps]\n",
        "  audio_features['audio'] = audio_features['audio'][:, :n_samples]\n",
        "\n",
        "  #Set up the model just to predict audio given new conditioning\n",
        "  model = ddsp.training.models.Autoencoder()\n",
        "  model.restore(ckpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSuV1jzkVCF1"
      },
      "source": [
        "def shift_loudness(audio_features, ld_shift=0.0):\n",
        "  #Shift loudness by a number of dB\n",
        "  audio_features['loudness_db'] += ld_shift\n",
        "  return audio_features\n",
        "\n",
        "\n",
        "def shift_f0(audio_features, octave_shift=0.0):\n",
        "  #Shift f0 by a number of octaves\n",
        "  audio_features['f0_hz'] *= 2.0 ** (octave_shift)\n",
        "  audio_features['f0_hz'] = np.clip(audio_features['f0_hz'], \n",
        "                                    0.0, \n",
        "                                    librosa.midi_to_hz(110.0))\n",
        "  return audio_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixt36c7Oj5G"
      },
      "source": [
        "def compute_audio_features():\n",
        "\n",
        "  global audio_features_mod, mask_on, loudness_norm, note_on_ratio, f0_midi_at\n",
        "\n",
        "  audio_features_mod = {k: v.copy() for k, v in audio_features.items()}\n",
        "\n",
        "  mask_on, note_on_ratio = detect_notes(audio_features['loudness_db'],\n",
        "                                        audio_features['f0_confidence'],\n",
        "                                        mask_threshold, \n",
        "                                        exponent=2.0)\n",
        "\n",
        "  if DATASET_STATS is not None:\n",
        "    _, loudness_norm = fit_quantile_transform(audio_features['loudness_db'],\n",
        "                                              mask_on,\n",
        "                                              inv_quantile=DATASET_STATS['quantile_transform'])\n",
        "\n",
        "    mask_off = np.logical_not(mask_on)\n",
        "    loudness_norm[mask_off] -=  quiet * (1.0 - note_on_ratio[mask_off][:, np.newaxis])\n",
        "    loudness_norm = np.reshape(loudness_norm, audio_features['loudness_db'].shape) \n",
        "    if use_norm:\n",
        "      audio_features_mod['loudness_db'] = loudness_norm \n",
        "\n",
        "\n",
        "  if autotune_amount > 0:\n",
        "    f0_midi = np.array(ddsp.core.hz_to_midi(audio_features_mod['f0_hz']))\n",
        "    tuning_factor = get_tuning_factor(f0_midi, audio_features_mod['f0_confidence'], mask_on)\n",
        "    f0_midi_at = auto_tune(f0_midi, tuning_factor, mask_on, amount=autotune_amount, chromatic=True)\n",
        "    audio_features_mod['f0_hz'] = ddsp.core.midi_to_hz(f0_midi_at)\n",
        "\n",
        "  audio_features_mod = shift_loudness(audio_features_mod, loudness_shift)\n",
        "  audio_features_mod = shift_f0(audio_features_mod, octave_shift)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5uSNclbRIxt"
      },
      "source": [
        "def run_model():\n",
        "\n",
        "  # Run a batch of predictions.\n",
        "  start_time = time.time()\n",
        "\n",
        "  outputs = model(audio_features_mod, training=False)\n",
        "  audio_gen = model.get_audio_from_outputs(outputs)\n",
        "\n",
        "  #Old code for DDSP v0.13.0\n",
        "  #controls =  model.get_controls(audio_features_mod, training=False)\n",
        "  #audio_gen = controls['processor_group']['signal']\n",
        "\n",
        "  #with out:\n",
        "  print('Prediction took %.1f seconds' % (time.time() - start_time))\n",
        "\n",
        "  # Plot\n",
        "  if full_output_checkbox.value:\n",
        "    print('Original')\n",
        "    play(audio)\n",
        "\n",
        "  print('Resynthesis')\n",
        "  play(audio_gen)\n",
        "\n",
        "  if full_output_checkbox.value:\n",
        "    specplot(audio)\n",
        "    plt.title(\"Original\")\n",
        "\n",
        "  specplot(audio_gen)\n",
        "  _ = plt.title(\"Resynthesis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeEM-oXCTTKV"
      },
      "source": [
        "def plot_data():\n",
        "  #auto octave adjustment.\n",
        "  pitch = ddsp.core.hz_to_midi(audio_features['f0_hz'])\n",
        "  example_mean_pitch = np.mean(pitch[mask_on])\n",
        "  if DATASET_STATS is not None:\n",
        "    instrument_mean_pitch = DATASET_STATS['mean_pitch']\n",
        "  else:\n",
        "    instrument_mean_pitch = example_mean_pitch\n",
        "  #p_diff = instrument_mean_pitch - example_mean_pitch\n",
        "  #p_diff_octave = p_diff / 12.0\n",
        "  #round_fn = np.floor if p_diff_octave > 1.5 else np.ceil\n",
        "  #p_diff_octave = round_fn(p_diff_octave)\n",
        "  #audio_features_mod = shift_f0(audio_features_mod, p_diff_octave)\n",
        "\n",
        "  #with out:\n",
        "  fig, ax = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(15.5, 10))\n",
        "  ax[0].plot(audio_features['loudness_db'])\n",
        "  if DATASET_STATS is not None:\n",
        "    ax[0].plot(loudness_norm)\n",
        "    ax[0].legend(['Original', 'Norm'])\n",
        "  else:\n",
        "    ax[0].legend(['Original'])\n",
        "  ax[0].set_ylabel('Loudness')\n",
        "  ax[0].set_ylim(-100,0)\n",
        "  ax[1].plot(librosa.hz_to_midi(audio_features['f0_hz']))\n",
        "  ax[1].plot(np.ones_like(mask_on) * instrument_mean_pitch, ':')\n",
        "  ax[1].plot(np.ones_like(mask_on) * example_mean_pitch, ':')\n",
        "  if autotune_amount > 0:\n",
        "    ax[1].plot(f0_midi_at)\n",
        "    ax[1].legend(['Pitch', 'Instrument pitch','Example pitch', 'autotune'])\n",
        "  else:\n",
        "    ax[1].legend(['Pitch', 'Instrument pitch','Example pitch'])\n",
        "  ax[1].set_ylabel('f0 [MIDI]')\n",
        "  ax[1].set_ylim(bottom=36)\n",
        "  ax[2].plot(audio_features['f0_confidence'])\n",
        "  ax[2].set_ylabel('f0 confidence')\n",
        "  ax[3].plot(note_on_ratio)\n",
        "  ax[3].plot(np.ones_like(mask_on) * mask_threshold, 'k:')\n",
        "  ax[3].plot(mask_on)\n",
        "  ax[3].set_ylabel('Note-on Mask')\n",
        "  ax[3].legend(['Note-on ratio', 'Threshold', 'Mask'])\n",
        "  _=ax[3].set_xlabel('Time step [frame]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeXVSdFBUE2u"
      },
      "source": [
        "#GUI components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63evlTH1UJ39"
      },
      "source": [
        "instrument_widget = widgets.Dropdown(options = instrument_file_list, value=instrument_file_list[0], description='Instrument:')\n",
        "example_widget = widgets.Dropdown(options = example_file_list, value=example_file_list[0], description='Example:')\n",
        "\n",
        "go_button = widgets.Button(\n",
        "    description='Transfer timbre',\n",
        "    button_style='primary', \n",
        "    layout=widgets.Layout(width='auto')\n",
        ")\n",
        "\n",
        "def go_eventhandler(change):\n",
        "  \n",
        "  global use_norm, mask_threshold, quiet, autotune_amount, octave_shift, loudness_shift\n",
        "\n",
        "  #out.clear_output()\n",
        "\n",
        "  use_norm = use_norm_checkbox.value\n",
        "  mask_threshold = mask_threshold_slider.value\n",
        "  quiet = quiet_slider.value\n",
        "  autotune_amount = autotune_amount_slider.value\n",
        "  octave_shift = octave_shift_slider.value\n",
        "  loudness_shift = loudness_shift_slider.value\n",
        "\n",
        "  #with out:\n",
        "  print()\n",
        "  print(\"EXAMPLE = '%s'\" % REALEXAMPLE)\n",
        "  print(\"INSTRUMENT = '%s\" % REALINSTRUMENT)\n",
        "  print('use_norm = %s' % ('True' if use_norm else 'False'))\n",
        "  print('mask_threshold = %.2f' % mask_threshold)\n",
        "  print('quiet = %d' % quiet)\n",
        "  print('autotune_amount = %.2f' % autotune_amount)\n",
        "  print('octave_shift = %.2f' % octave_shift)\n",
        "  print('loudness_shift = %d' % loudness_shift)\n",
        "  print()\n",
        "\n",
        "  compute_audio_features()\n",
        "  run_model()\n",
        "  if full_output_checkbox.value:\n",
        "    plot_data()\n",
        "\n",
        "go_button.on_click(go_eventhandler)\n",
        "\n",
        "full_output_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Show full output'\n",
        ")\n",
        "\n",
        "use_norm_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Use loudness statistics'\n",
        ")\n",
        "\n",
        "mask_threshold_slider = widgets.FloatSlider(\n",
        "    value=1,\n",
        "    min=0,\n",
        "    max=2,\n",
        "    step=0.1,\n",
        "    description='Mask threshold:',\n",
        "    continuous_update=False,\n",
        "    readout=True,\n",
        "    readout_format='.1f',\n",
        ")\n",
        "\n",
        "quiet_slider = widgets.IntSlider(\n",
        "    value=20,\n",
        "    min=0,\n",
        "    max=50,\n",
        "    step=1,\n",
        "    description='Attenuation:',\n",
        "    continuous_update=False,\n",
        "    readout=True,\n",
        "    readout_format='d'\n",
        ")\n",
        "autotune_amount_slider = widgets.FloatSlider(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=1,\n",
        "    step=0.1,\n",
        "    description='Autotune:',\n",
        "    continuous_update=False,\n",
        "    readout=True,\n",
        "    readout_format='.1f',\n",
        ")\n",
        "octave_shift_slider = widgets.IntSlider(\n",
        "    value=0,\n",
        "    min=-3,\n",
        "    max=3,\n",
        "    step=1,\n",
        "    description='Octave shift:',\n",
        "    continuous_update=False,\n",
        "    readout=True,\n",
        "    readout_format='d'\n",
        ")\n",
        "\n",
        "loudness_shift_slider = widgets.IntSlider(\n",
        "    value=0,\n",
        "    min=-30,\n",
        "    max=30,\n",
        "    step=5,\n",
        "    description='Loudness shift:',\n",
        "    continuous_update=False,\n",
        "    readout=True,\n",
        "    readout_format='d'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msHYBIy19FE7"
      },
      "source": [
        "#Set instrument and example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "LYJVJZFWjgIO"
      },
      "source": [
        "interact(load_instrument, instrument_name=instrument_widget)\n",
        "interact(load_example, example_name=example_widget)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7vulQQeiPcI"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kQw32hGA-g3"
      },
      "source": [
        "#Improve loudness with statistical info\n",
        "display(full_output_checkbox)\n",
        "display(use_norm_checkbox)\n",
        "display(mask_threshold_slider)\n",
        "display(quiet_slider)\n",
        "\n",
        "#Improve pitch\n",
        "display(autotune_amount_slider)\n",
        "\n",
        "#Adjust source material to model pitch and loudness\n",
        "display(octave_shift_slider)\n",
        "display(loudness_shift_slider)\n",
        "\n",
        "display(go_button)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}