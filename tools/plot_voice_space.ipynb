{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plot_voice_space",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpeHEfn/XQurWXC4OZl6M3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPZ39tHdBO5f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEwfkNbvowzs"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, os\n",
        "\n",
        "%config InlineBackend.figure_format='retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLRJ7pjTpHl0"
      },
      "source": [
        "#instrument_list = ['servando', 'belen', 'eva', 'mrallsop', 'alba'] \n",
        "instrument_list = ['servando','belen', 'eva', 'voices3',  'voices2'] \n",
        "\n",
        "DRIVE_BASE_DIR = '/content/drive/My Drive/SMC 09/DDSP/audio'\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "legend=[]\n",
        "\n",
        "for INSTRUMENT in instrument_list:\n",
        "\n",
        "  LOG_DIR = DRIVE_BASE_DIR + '/' + INSTRUMENT + \\\n",
        "              '_checkpoints/summaries/train/'\n",
        "  print(\"Analyzing\", LOG_DIR)\n",
        "  if (INSTRUMENT == 'voices2'):\n",
        "    legend.append('voices2: eva + belen')\n",
        "  elif (INSTRUMENT == 'voices3'):\n",
        "    legend.append('voices3: eva + belen + servando')\n",
        "  else:\n",
        "    legend.append(INSTRUMENT)\n",
        "\n",
        "  os.chdir(LOG_DIR)\n",
        "  logs=[]\n",
        "  for file in glob.glob(\"*.v2\"):\n",
        "      logs.append(file)\n",
        "\n",
        "  losses = {}\n",
        "  for log_file in logs:\n",
        "      for e in tf.compat.v1.train.summary_iterator(LOG_DIR+log_file):\n",
        "          for v in e.summary.value:\n",
        "              if v.tag == 'losses/total_loss':\n",
        "                  tensor_array = tf.io.decode_raw(v.tensor.tensor_content, v.tensor.dtype)\n",
        "                  losses[e.step] = tensor_array[0]\n",
        "                  if e.step==40000:\n",
        "                    print(tensor_array[0])\n",
        "                    \n",
        "  #dash = ':' if (INSTRUMENT=='alba' or INSTRUMENT=='mrallsop') else '-'\n",
        "  #width = 1.5\n",
        "  \n",
        "  dash = '-' if (INSTRUMENT=='voices3' or INSTRUMENT=='voices2') else ':'\n",
        "  width = 1.5\n",
        "\n",
        "  ax.plot(list(losses.keys()), list(losses.values()), dash, linewidth=width)\n",
        "\n",
        "ax.set_ylabel('total loss')\n",
        "ax.set_xlabel('steps')\n",
        "ax.legend(legend)\n",
        "ax.set_xlim((0,40000))\n",
        "ax.grid(b=True)\n",
        "_ = ax.set_ylim((4.5,9))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}